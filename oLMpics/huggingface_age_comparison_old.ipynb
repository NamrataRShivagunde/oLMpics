{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e163e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import transformers\n",
    "import wandb\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s: %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64aee282",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CustomArguments(transformers.TrainingArguments):\n",
    "    sample_train: int = 0\n",
    "    sample_eval: int = 0\n",
    "    num_choices: int = 0\n",
    "    model_name_or_path: str = \"asdf\"  # this is no longer a TrainingArgument attribute\n",
    "        \n",
    "    # python dataclasses cannot have positional attributes in subclass,\n",
    "    # so give all attributes defaults and then make sure they are changed\n",
    "    def __post_init__(self):\n",
    "        if not (self.sample_train * self.sample_eval * self.num_choices) or \\\n",
    "               self.model_name_or_path == \"asdf\":  # make sure none are still default value\n",
    "            raise TypeError(\"__init__ missing required argument(s)\")\n",
    "\n",
    "def get_args():\n",
    "    \"\"\" Set hyperparameters \"\"\"\n",
    "    args = CustomArguments(\n",
    "        output_dir=\"checkpoint\",\n",
    "        model_name_or_path=\"roberta-base\",\n",
    "        overwrite_output_dir=True,\n",
    "        do_train=False,  # Zero shot\n",
    "        do_eval=True,\n",
    "        per_device_eval_batch_size=8,\n",
    "        learning_rate=1e-5,  # Should not matter because not training\n",
    "        weight_decay=0.1,\n",
    "        save_total_limit=2,\n",
    "        seed=123,\n",
    "        sample_train=200,\n",
    "        sample_eval=-1,\n",
    "        num_choices=2,\n",
    "    )\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b031c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_path, sample, num_choices):\n",
    "    data_file = open(file_path, \"r\")\n",
    "    logger.info(\"Reading QA instances from jsonl dataset at: %s\", file_path)\n",
    "    item_jsons = []\n",
    "    item_ids = []\n",
    "    questions = []\n",
    "    choice_lists = []\n",
    "    answer_ids = []\n",
    "    for line in data_file:\n",
    "        item_jsons.append(json.loads(line.strip()))\n",
    "\n",
    "    if sample != -1:\n",
    "        item_jsons = random.sample(item_jsons, sample)\n",
    "        logger.info(\"Sampling %d examples\", sample)\n",
    "\n",
    "    for item_json in tqdm(item_jsons,total=len(item_jsons)):\n",
    "        item_id = item_json[\"id\"]\n",
    "\n",
    "        question_text = item_json[\"question\"][\"stem\"]\n",
    "\n",
    "        choice_label_to_id = {}\n",
    "        choice_text_list = []\n",
    "        choice_context_list = []\n",
    "        choice_label_list = []\n",
    "        choice_annotations_list = []\n",
    "\n",
    "        any_correct = False\n",
    "        choice_id_correction = 0\n",
    "\n",
    "        for choice_id, choice_item in enumerate(item_json[\"question\"][\"choices\"]):\n",
    "            choice_label = choice_item[\"label\"]\n",
    "            choice_label_to_id[choice_label] = choice_id - choice_id_correction\n",
    "            choice_text = choice_item[\"text\"]\n",
    "\n",
    "            choice_text_list.append(choice_text)\n",
    "            choice_label_list.append(choice_label)\n",
    "\n",
    "            if item_json.get('answerKey') == choice_label:\n",
    "                if any_correct:\n",
    "                    raise ValueError(\"More than one correct answer found for {item_json}!\")\n",
    "                any_correct = True\n",
    "\n",
    "\n",
    "        if not any_correct and 'answerKey' in item_json:\n",
    "            raise ValueError(\"No correct answer found for {item_json}!\")\n",
    "\n",
    "\n",
    "        answer_id = choice_label_to_id.get(item_json.get(\"answerKey\"))\n",
    "        # Pad choices with empty strings if not right number\n",
    "        if len(choice_text_list) != num_choices:\n",
    "            choice_text_list = (choice_text_list + num_choices * [''])[:num_choices]\n",
    "            choice_context_list = (choice_context_list + num_choices * [None])[:num_choices]\n",
    "            if answer_id is not None and answer_id >= num_choices:\n",
    "                logging.warning(f\"Skipping question with more than {num_choices} answers: {item_json}\")\n",
    "                continue\n",
    "\n",
    "        item_ids.append(item_id)\n",
    "        questions.append(question_text)\n",
    "        choice_lists.append(choice_text_list)\n",
    "        answer_ids.append(answer_id)\n",
    "\n",
    "    data_file.close()\n",
    "    return questions, choice_lists, answer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4d7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer):\n",
    "        out = tokenizer(questions)\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.token_type_ids = out[\"token_type_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"token_type_ids\": self.token_type_ids[i],\n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }\n",
    "    \n",
    "\n",
    "class RoBERTaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer, rep=True):\n",
    "        if rep:\n",
    "            questions = [question.replace('[MASK]','<mask>') for question in questions]\n",
    "        out = tokenizer(questions)\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f035fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer, eval_dataset):\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.per_device_eval_batch_size)\n",
    "\n",
    "    logger.info(f\"***** Running evaluation  *****\")\n",
    "    logger.info(f\"  Num examples = {len(eval_dataset)}\")\n",
    "    logger.info(f\"  Batch size = {args.eval_batch_size}\")\n",
    "    eval_dataloader = tqdm(eval_dataloader, desc=\"Evaluating\")\n",
    "    \n",
    "    YOUNG_ID = tokenizer.encode(\" younger\", add_special_tokens=False)\n",
    "    OLD_ID = tokenizer.encode(\" older\", add_special_tokens=False)\n",
    "    YEAR_ID = tokenizer.encode(\" year\", add_special_tokens=False)\n",
    "    MASK_ID = tokenizer.encode(\"<mask>\" if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\", \"distil\")) else \"[MASK]\", add_special_tokens=False)\n",
    "    assert len(YOUNG_ID) == 1 and len(OLD_ID) == 1 and len(YEAR_ID) == 1 and len(MASK_ID) == 1\n",
    "    YOUNG_ID = YOUNG_ID[0]\n",
    "    OLD_ID = OLD_ID[0]\n",
    "    YEAR_ID = YEAR_ID[0]\n",
    "    MASK_ID = MASK_ID[0]\n",
    "    YEAR_INDEX1 = eval_dataset[0][\"input_ids\"].index(YEAR_ID)  # Assuming it's the same for the rest\n",
    "    YEAR_INDEX2 = eval_dataset[0][\"input_ids\"].index(YEAR_ID, YEAR_INDEX1+1)\n",
    "    MASK_INDEX = eval_dataset[0][\"input_ids\"].index(MASK_ID)\n",
    "    \n",
    "    all_answers = []\n",
    "    all_preds = []\n",
    "    first_age = []\n",
    "    second_age = []\n",
    "    c = 0\n",
    "    for batch in eval_dataloader:\n",
    "        model.eval()\n",
    "        \n",
    "        for i in range(len(batch[\"answer_id\"])):\n",
    "            if batch[\"choice_list\"][0][i] == \"older\":\n",
    "                batch[\"answer_id\"][i] = -batch[\"answer_id\"][i] + 1  # Flip 1 -> 0, 0 -> 1\n",
    "        \n",
    "        all_answers.extend(batch[\"answer_id\"].tolist())\n",
    "        \n",
    "        del batch[\"choice_list\"] \n",
    "        for key in batch:\n",
    "            if key != \"answer_id\":\n",
    "                batch[key] = torch.stack(batch[key], dim=-1)\n",
    "\n",
    "            batch[key] = batch[key].cuda()\n",
    "            \n",
    "        age1 = tokenizer.decode(batch[\"input_ids\"][:, YEAR_INDEX1 - 1]).lstrip().split(\" \")\n",
    "        age2 = tokenizer.decode(batch[\"input_ids\"][:, YEAR_INDEX2 - 1]).lstrip().split(\" \")\n",
    "        \n",
    "        first_age.extend(age1)\n",
    "        second_age.extend(age2)\n",
    "        answer_ids = batch.pop(\"answer_id\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "        \n",
    "        preds = torch.gt(logits[:, MASK_INDEX, OLD_ID], logits[:, MASK_INDEX, YOUNG_ID])\n",
    "        all_preds.extend(preds.tolist())\n",
    "        \n",
    "    first_age = [int(age) for age in first_age]\n",
    "    second_age = [int(age) for age in second_age]\n",
    "    return all_answers, all_preds, first_age, second_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4dc1b65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "05/19/2021 15:32:30: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_train.jsonl\n",
      "05/19/2021 15:32:30: Sampling 200 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8f4b309d3d45e5b0aa84e48a3d687d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/19/2021 15:32:30: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af17155d80dc4f07907a14b647907c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = get_args()\n",
    "args.model_name_or_path = \"bert-large-uncased\" # \"bert-large-uncased-whole-word-masking\"  # \"roberta-large\"\n",
    "transformers.set_seed(args.seed)\n",
    "model = transformers.AutoModelForMaskedLM.from_pretrained(args.model_name_or_path).cuda()\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "train_questions, train_choices, train_answer_ids = get_data(\"data/number_comparison_age_compare_masked_train.jsonl\", args.sample_train, args.num_choices)\n",
    "eval_questions, eval_choices, eval_answer_ids = get_data(\"data/number_comparison_age_compare_masked_dev.jsonl\", args.sample_eval, args.num_choices)\n",
    "assert \"t5\" not in args.model_name_or_path.lower()\n",
    "AgeDataset = RoBERTaDataset if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\", \"distil\", \"electra\")) else BERTDataset\n",
    "if \"electra\" in args.model_name_or_path.lower():\n",
    "    train_dataset = AgeDataset(train_questions, train_choices, train_answer_ids, tokenizer, rep=False)\n",
    "    eval_dataset = AgeDataset(eval_questions, eval_choices, eval_answer_ids, tokenizer, rep=False)\n",
    "else:\n",
    "    train_dataset = AgeDataset(train_questions, train_choices, train_answer_ids, tokenizer)\n",
    "    eval_dataset = AgeDataset(eval_questions, eval_choices, eval_answer_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6e8937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/19/2021 15:32:32: ***** Running evaluation  *****\n",
      "05/19/2021 15:32:32:   Num examples = 500\n",
      "05/19/2021 15:32:32:   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e25a82212b4969840fe6737bad1cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_answers, all_preds, first_age, second_age = evaluate(args, model, tokenizer, eval_dataset)\n",
    "# correct = [1 if all_answers[i] == all_preds[i] else 0 for i in range(len(all_answers))]\n",
    "# print(np.array(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ef19339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(first_age, second_age, c=all_preds, marker=\"s\")\n",
    "plt.title(f\"Age Comparison {args.model_name_or_path}\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"Age 1\")\n",
    "plt.ylabel(\"Age 2\")\n",
    "plt.savefig(f\"imgs/{args.model_name_or_path.rsplit('/', 1)[-1]}-ages-double.jpg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5549e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
