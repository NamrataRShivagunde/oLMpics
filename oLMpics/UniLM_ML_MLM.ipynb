{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "UniLM_ML_MLM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7e7d9f677e774af2bc68bc3df49d9cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f7f5ed5f219746799c9702eb5c82d699",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1128bd5913ef4b61a05b167ec64b16a6",
              "IPY_MODEL_fa952b6e1ceb4f84a859098279dd8725",
              "IPY_MODEL_92d73914b27944d78b8a3d61a3b169c7"
            ]
          }
        },
        "f7f5ed5f219746799c9702eb5c82d699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1128bd5913ef4b61a05b167ec64b16a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b9832aada6374668a70de1330bf6306b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c7aa393e618485d8071eae65945d35a"
          }
        },
        "fa952b6e1ceb4f84a859098279dd8725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3f6d7d924af14ad6a0474d991e56dd94",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a2f01d43be04d8db4446f135a7cab88"
          }
        },
        "92d73914b27944d78b8a3d61a3b169c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d896de7f7210490ba9e29f6aafd35b2b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 208k/208k [00:00&lt;00:00, 637kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b99c065009354752932273925505ed1c"
          }
        },
        "b9832aada6374668a70de1330bf6306b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c7aa393e618485d8071eae65945d35a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f6d7d924af14ad6a0474d991e56dd94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a2f01d43be04d8db4446f135a7cab88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d896de7f7210490ba9e29f6aafd35b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b99c065009354752932273925505ed1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e41e1173dd449a690183dadb84177b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eb782844bb9f4321ace8a8510614591e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_082aec318c6d442fb448578ccf76855e",
              "IPY_MODEL_be01900fcfe44db499a842fe9fd074e6",
              "IPY_MODEL_0e3ec04d027d43bea8660a81f9ff2bb3"
            ]
          }
        },
        "eb782844bb9f4321ace8a8510614591e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "082aec318c6d442fb448578ccf76855e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad8cd37ac9d54ee5ac16d61aa6c183f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e64eb7e584843d695ca0530a19424e8"
          }
        },
        "be01900fcfe44db499a842fe9fd074e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dcab8d0e76664086a497d515ad02f55f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99a6fd9303c64771b8ff9515c76599e6"
          }
        },
        "0e3ec04d027d43bea8660a81f9ff2bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6dc9ffa1e5094c4bbc30400295d48e2f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 638B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_021031545830474c87dcd7bc71b8dc0e"
          }
        },
        "ad8cd37ac9d54ee5ac16d61aa6c183f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e64eb7e584843d695ca0530a19424e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dcab8d0e76664086a497d515ad02f55f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99a6fd9303c64771b8ff9515c76599e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6dc9ffa1e5094c4bbc30400295d48e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "021031545830474c87dcd7bc71b8dc0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "289abd6fe70b46b49bee2b845bfd0deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ba012ffd296646d5aeaef04daec54c90",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b5e5958d2c494645accc24f43369e0d9",
              "IPY_MODEL_c5c4e479d8a9447db84ed8a707e65584",
              "IPY_MODEL_8f1696c9c0764a568ce8cff4cc9750f9"
            ]
          }
        },
        "ba012ffd296646d5aeaef04daec54c90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5e5958d2c494645accc24f43369e0d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8c971e801f74dbeb599ecbea704ffcf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2465b9360fe94035ade4317d6a96bdbb"
          }
        },
        "c5c4e479d8a9447db84ed8a707e65584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1d259aa4292d4770ba02b8eed1414773",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f790435a44c46b0b226edd78cc18e52"
          }
        },
        "8f1696c9c0764a568ce8cff4cc9750f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_27a4729b4fff44ef8fc0826fc878c4d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 426k/426k [00:00&lt;00:00, 730kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_267654aab2ea43eb81fd8e6ad3a9afbb"
          }
        },
        "c8c971e801f74dbeb599ecbea704ffcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2465b9360fe94035ade4317d6a96bdbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d259aa4292d4770ba02b8eed1414773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f790435a44c46b0b226edd78cc18e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27a4729b4fff44ef8fc0826fc878c4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "267654aab2ea43eb81fd8e6ad3a9afbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "507cfe6b5a464a1d9f7a32f31c640aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e799f80affb416b988cd2171094ea5b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ba03b269e9424b779228654bc1399cfb",
              "IPY_MODEL_6ae2518abc8b43939817c394c420da60",
              "IPY_MODEL_687f7172466047268fe3c360a8e81519"
            ]
          }
        },
        "9e799f80affb416b988cd2171094ea5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba03b269e9424b779228654bc1399cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06fce531e31b4841a7670099b976163c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eadcd4bf8f4b4d76bc4a958525a91f26"
          }
        },
        "6ae2518abc8b43939817c394c420da60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4e6e3da3dda344c396655ee9ea3515e2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 762,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 762,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb19b1a32c854d55bdb210f7528320b6"
          }
        },
        "687f7172466047268fe3c360a8e81519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f9b074f529f44187baece292cd1a824f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 762/762 [00:00&lt;00:00, 16.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d8f82001bea43ca81bae440cfa4f73c"
          }
        },
        "06fce531e31b4841a7670099b976163c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eadcd4bf8f4b4d76bc4a958525a91f26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e6e3da3dda344c396655ee9ea3515e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb19b1a32c854d55bdb210f7528320b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9b074f529f44187baece292cd1a824f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d8f82001bea43ca81bae440cfa4f73c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "xMRV7BmfM0zc",
        "outputId": "0183a76f-ee9d-4145-bf73-eb171c5c7f71"
      },
      "source": [
        "!pip install torch==0.4.0\n",
        "!pip install --upgrade six"
      ],
      "id": "xMRV7BmfM0zc",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==0.4.0 (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2, 0.4.1, 0.4.1.post2, 1.0.0, 1.0.1, 1.0.1.post2, 1.1.0, 1.2.0, 1.3.0, 1.3.1, 1.4.0, 1.5.0, 1.5.1, 1.6.0, 1.7.0, 1.7.1, 1.8.0, 1.8.1, 1.9.0, 1.9.1)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for torch==0.4.0\u001b[0m\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (1.15.0)\n",
            "Collecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: six\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed six-1.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5TfBhsqqaFL",
        "outputId": "c98e9ef4-76e5-466c-c2a8-43538146798a"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install boto3"
      ],
      "id": "O5TfBhsqqaFL",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 40.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 39.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.18.63-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting botocore<1.22.0,>=1.21.63\n",
            "  Downloading botocore-1.21.63-py3-none-any.whl (8.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 42.8 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.63->boto3) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 46.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.63->boto3) (1.16.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.7 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.18.63 botocore-1.21.63 jmespath-0.10.0 s3transfer-0.5.0 urllib3-1.26.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7JWFmPFKMs2",
        "outputId": "32579425-6ffb-4094-e0a3-d011a4c6e7b6"
      },
      "source": [
        "!git clone https://github.com/microsoft/unilm.git"
      ],
      "id": "F7JWFmPFKMs2",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'unilm'...\n",
            "remote: Enumerating objects: 3121, done.\u001b[K\n",
            "remote: Counting objects: 100% (2272/2272), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1777/1777), done.\u001b[K\n",
            "remote: Total 3121 (delta 942), reused 1585 (delta 419), pack-reused 849\u001b[K\n",
            "Receiving objects: 100% (3121/3121), 5.22 MiB | 16.15 MiB/s, done.\n",
            "Resolving deltas: 100% (1413/1413), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahJYT_ngKSYf"
      },
      "source": [
        "import os\n",
        "os.chdir(\"unilm/unilm-v1/src\")\n"
      ],
      "id": "ahJYT_ngKSYf",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCX771N5KqPh",
        "outputId": "a0adb357-fee3-4e85-a01b-99406814c718"
      },
      "source": [
        "ls"
      ],
      "id": "FCX771N5KqPh",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mbiunilm\u001b[0m/  \u001b[01;34mcnndm\u001b[0m/  \u001b[01;34mgigaword\u001b[0m/  \u001b[01;34mnn\u001b[0m/  \u001b[01;34mpytorch_pretrained_bert\u001b[0m/  \u001b[01;34mqg\u001b[0m/  setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e163e358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e00e4bd-2cc8-422f-c498-4f7b9c86b38d"
      },
      "source": [
        "import argparse\n",
        "from dataclasses import dataclass\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import numpy as np\n",
        "import scipy.stats as st\n",
        "\n",
        "import transformers\n",
        "#import wandb\n",
        "from tqdm.auto import tqdm, trange\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s: %(message)s\",\n",
        "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "    level=logging.INFO,\n",
        ")"
      ],
      "id": "e163e358",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64aee282"
      },
      "source": [
        "@dataclass\n",
        "class CustomArguments(transformers.TrainingArguments):\n",
        "    sample_train: int = 0\n",
        "    sample_eval: int = 0\n",
        "    num_choices: int = 0\n",
        "    model_name_or_path: str = \"asdf\"  # this is no longer a TrainingArgument attribute\n",
        "        \n",
        "    # python dataclasses cannot have positional attributes in subclass,\n",
        "    # so give all attributes defaults and then make sure they are changed\n",
        "    def __post_init__(self):\n",
        "        if not (self.sample_train * self.sample_eval * self.num_choices) or \\\n",
        "               self.model_name_or_path == \"asdf\":  # make sure none are still default value\n",
        "            raise TypeError(\"__init__ missing required argument(s)\")\n",
        "\n",
        "def get_args():\n",
        "    \"\"\" Set hyperparameters \"\"\"\n",
        "    args = CustomArguments(\n",
        "        output_dir=\"checkpoint\",\n",
        "        model_name_or_path=\"roberta-base\",\n",
        "        overwrite_output_dir=True,\n",
        "        do_train=False,  # Zero shot\n",
        "        do_eval=True,\n",
        "        per_device_eval_batch_size=2,\n",
        "        learning_rate=1e-5,  # Should not matter because not training\n",
        "        weight_decay=0.1,\n",
        "        save_total_limit=2,\n",
        "        seed=254,\n",
        "        sample_train=200,\n",
        "        sample_eval=-1,\n",
        "        num_choices=5,\n",
        "    )\n",
        "    \n",
        "    return args"
      ],
      "id": "64aee282",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b031c07"
      },
      "source": [
        "def get_data(file_path, sample, num_choices):\n",
        "    data_file = open(file_path, \"r\")\n",
        "    logger.info(\"Reading QA instances from jsonl dataset at: %s\", file_path)\n",
        "    item_jsons = []\n",
        "    item_ids = []\n",
        "    questions = []\n",
        "    choice_lists = []\n",
        "    answer_ids = []\n",
        "    for line in data_file:\n",
        "        item_jsons.append(json.loads(line.strip()))\n",
        "\n",
        "    if sample != -1:\n",
        "        item_jsons = random.sample(item_jsons, sample)\n",
        "        logger.info(\"Sampling %d examples\", sample)\n",
        "\n",
        "    for item_json in tqdm(item_jsons,total=len(item_jsons)):\n",
        "        item_id = item_json[\"id\"]\n",
        "\n",
        "        question_text = item_json[\"question\"][\"stem\"]\n",
        "\n",
        "        choice_label_to_id = {}\n",
        "        choice_text_list = []\n",
        "        choice_context_list = []\n",
        "        choice_label_list = []\n",
        "        choice_annotations_list = []\n",
        "\n",
        "        any_correct = False\n",
        "        choice_id_correction = 0\n",
        "\n",
        "        for choice_id, choice_item in enumerate(item_json[\"question\"][\"choices\"]):\n",
        "            choice_label = choice_item[\"label\"]\n",
        "            choice_label_to_id[choice_label] = choice_id - choice_id_correction\n",
        "            choice_text = choice_item[\"text\"]\n",
        "\n",
        "            choice_text_list.append(choice_text)\n",
        "            choice_label_list.append(choice_label)\n",
        "\n",
        "            if item_json.get('answerKey') == choice_label:\n",
        "                if any_correct:\n",
        "                    raise ValueError(\"More than one correct answer found for {item_json}!\")\n",
        "                any_correct = True\n",
        "\n",
        "\n",
        "        if not any_correct and 'answerKey' in item_json:\n",
        "            raise ValueError(\"No correct answer found for {item_json}!\")\n",
        "\n",
        "\n",
        "        answer_id = choice_label_to_id.get(item_json.get(\"answerKey\"))\n",
        "        # Pad choices with empty strings if not right number\n",
        "        if len(choice_text_list) != num_choices:\n",
        "            choice_text_list = (choice_text_list + num_choices * [''])[:num_choices]\n",
        "            choice_context_list = (choice_context_list + num_choices * [None])[:num_choices]\n",
        "            if answer_id is not None and answer_id >= num_choices:\n",
        "                logging.warning(f\"Skipping question with more than {num_choices} answers: {item_json}\")\n",
        "                continue\n",
        "\n",
        "        item_ids.append(item_id)\n",
        "        questions.append(question_text)\n",
        "        choice_lists.append(choice_text_list)\n",
        "        answer_ids.append(answer_id)\n",
        "\n",
        "    data_file.close()\n",
        "    return questions, choice_lists, answer_ids"
      ],
      "id": "0b031c07",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e4d7c36"
      },
      "source": [
        "class BERTDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, questions, choices, answer_ids, tokenizer):\n",
        "        out = tokenizer(questions, max_length=25, padding=\"max_length\")\n",
        "        self.input_ids = out[\"input_ids\"]\n",
        "        self.token_type_ids = out[\"token_type_ids\"]\n",
        "        self.attention_mask = out[\"attention_mask\"]\n",
        "        self.questions = questions\n",
        "        self.choices = choices\n",
        "        self.answer_ids = answer_ids\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return {\n",
        "            \"input_ids\": self.input_ids[i], \n",
        "            \"attention_mask\": self.attention_mask[i], \n",
        "            \"token_type_ids\": self.token_type_ids[i],\n",
        "            \"choice_list\": self.choices[i], \n",
        "            \"answer_id\": self.answer_ids[i],\n",
        "        }\n",
        "    \n",
        "\n",
        "class RoBERTaDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, questions, choices, answer_ids, tokenizer):\n",
        "#         if \"t5\" in tokenizer.name_or_path.lower():\n",
        "#             questions = [question.replace('[MASK]', '') for question in questions]\n",
        "#         else:\n",
        "        questions = [question.replace('[MASK]', tokenizer.mask_token) for question in questions]\n",
        "        out = tokenizer(questions, max_length=25, padding=\"max_length\")\n",
        "        self.input_ids = out[\"input_ids\"]\n",
        "        self.attention_mask = out[\"attention_mask\"]\n",
        "        self.questions = questions\n",
        "        self.choices = choices\n",
        "        self.answer_ids = answer_ids\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return {\n",
        "            \"input_ids\": self.input_ids[i], \n",
        "            \"attention_mask\": self.attention_mask[i], \n",
        "            \"choice_list\": self.choices[i], \n",
        "            \"answer_id\": self.answer_ids[i],\n",
        "        }"
      ],
      "id": "6e4d7c36",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qWezD_DofGHl",
        "outputId": "c56770bd-28b0-473f-b9db-8383c5a56ebd"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "os.getcwd()"
      ],
      "id": "qWezD_DofGHl",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/unilm/unilm-v1/src'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2T4hdixACE0"
      },
      "source": [
        "#restart runtime\n",
        "from biunilm import *\n",
        "from pytorch_pretrained_bert.modeling import *\n",
        "from pytorch_pretrained_bert.file_utils import *"
      ],
      "id": "s2T4hdixACE0",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NA98DmJQWUV",
        "outputId": "2c3df7fd-24eb-4617-b74d-4cf4702f8959"
      },
      "source": [
        "!wget https://unilm.blob.core.windows.net/ckpt/unilm1-base-cased.bin\n",
        "!wget https://unilm.blob.core.windows.net/ckpt/unilm1-large-cased.bin"
      ],
      "id": "4NA98DmJQWUV",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-18 13:47:16--  https://unilm.blob.core.windows.net/ckpt/unilm1-base-cased.bin\n",
            "Resolving unilm.blob.core.windows.net (unilm.blob.core.windows.net)... 52.239.193.100\n",
            "Connecting to unilm.blob.core.windows.net (unilm.blob.core.windows.net)|52.239.193.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 217918554 (208M) [application/octet-stream]\n",
            "Saving to: ‘unilm1-base-cased.bin’\n",
            "\n",
            "unilm1-base-cased.b 100%[===================>] 207.82M  14.0MB/s    in 17s     \n",
            "\n",
            "2021-10-18 13:47:33 (12.5 MB/s) - ‘unilm1-base-cased.bin’ saved [217918554/217918554]\n",
            "\n",
            "--2021-10-18 13:47:33--  https://unilm.blob.core.windows.net/ckpt/unilm1-large-cased.bin\n",
            "Resolving unilm.blob.core.windows.net (unilm.blob.core.windows.net)... 52.239.193.100\n",
            "Connecting to unilm.blob.core.windows.net (unilm.blob.core.windows.net)|52.239.193.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 669422755 (638M) [application/octet-stream]\n",
            "Saving to: ‘unilm1-large-cased.bin’\n",
            "\n",
            "unilm1-large-cased. 100%[===================>] 638.41M  12.4MB/s    in 51s     \n",
            "\n",
            "2021-10-18 13:48:25 (12.6 MB/s) - ‘unilm1-large-cased.bin’ saved [669422755/669422755]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7e7d9f677e774af2bc68bc3df49d9cb2",
            "f7f5ed5f219746799c9702eb5c82d699",
            "1128bd5913ef4b61a05b167ec64b16a6",
            "fa952b6e1ceb4f84a859098279dd8725",
            "92d73914b27944d78b8a3d61a3b169c7",
            "b9832aada6374668a70de1330bf6306b",
            "4c7aa393e618485d8071eae65945d35a",
            "3f6d7d924af14ad6a0474d991e56dd94",
            "2a2f01d43be04d8db4446f135a7cab88",
            "d896de7f7210490ba9e29f6aafd35b2b",
            "b99c065009354752932273925505ed1c",
            "7e41e1173dd449a690183dadb84177b6",
            "eb782844bb9f4321ace8a8510614591e",
            "082aec318c6d442fb448578ccf76855e",
            "be01900fcfe44db499a842fe9fd074e6",
            "0e3ec04d027d43bea8660a81f9ff2bb3",
            "ad8cd37ac9d54ee5ac16d61aa6c183f6",
            "8e64eb7e584843d695ca0530a19424e8",
            "dcab8d0e76664086a497d515ad02f55f",
            "99a6fd9303c64771b8ff9515c76599e6",
            "6dc9ffa1e5094c4bbc30400295d48e2f",
            "021031545830474c87dcd7bc71b8dc0e",
            "289abd6fe70b46b49bee2b845bfd0deb",
            "ba012ffd296646d5aeaef04daec54c90",
            "b5e5958d2c494645accc24f43369e0d9",
            "c5c4e479d8a9447db84ed8a707e65584",
            "8f1696c9c0764a568ce8cff4cc9750f9",
            "c8c971e801f74dbeb599ecbea704ffcf",
            "2465b9360fe94035ade4317d6a96bdbb",
            "1d259aa4292d4770ba02b8eed1414773",
            "4f790435a44c46b0b226edd78cc18e52",
            "27a4729b4fff44ef8fc0826fc878c4d5",
            "267654aab2ea43eb81fd8e6ad3a9afbb",
            "507cfe6b5a464a1d9f7a32f31c640aa0",
            "9e799f80affb416b988cd2171094ea5b",
            "ba03b269e9424b779228654bc1399cfb",
            "6ae2518abc8b43939817c394c420da60",
            "687f7172466047268fe3c360a8e81519",
            "06fce531e31b4841a7670099b976163c",
            "eadcd4bf8f4b4d76bc4a958525a91f26",
            "4e6e3da3dda344c396655ee9ea3515e2",
            "fb19b1a32c854d55bdb210f7528320b6",
            "f9b074f529f44187baece292cd1a824f",
            "5d8f82001bea43ca81bae440cfa4f73c"
          ]
        },
        "id": "d4dc1b65",
        "scrolled": true,
        "outputId": "27cff002-1534-4aaa-ad93-5f28ef6d7b0b"
      },
      "source": [
        "import math\n",
        "import os\n",
        "import logging\n",
        "import shutil\n",
        "import tempfile\n",
        "import json\n",
        "from urllib.parse import urlparse\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple, Union, IO, Callable, Set\n",
        "from hashlib import sha256\n",
        "from functools import wraps\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import boto3\n",
        "from botocore.exceptions import ClientError\n",
        "import requests\n",
        "args = get_args()\n",
        "'''\n",
        "\"bert-base-uncased\"\n",
        "\"bert-large-uncased\"\n",
        "'''\n",
        "\n",
        "type_vocab_size = 6\n",
        "args.model_name_or_path = \"bert-large-cased\"\n",
        "transformers.set_seed(args.seed)\n",
        "\n",
        "model = BertForPreTrainingLossMask.from_pretrained(args.model_name_or_path, num_rel=0, type_vocab_size=type_vocab_size).cuda()\n",
        "model.load_state_dict(torch.load('unilm1-large-cased.bin', map_location=torch.device('cuda')))\n",
        "\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(args.model_name_or_path)"
      ],
      "id": "d4dc1b65",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10/18/2021 13:48:25: https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz not found in cache, downloading to /tmp/tmpkkecojnc\n",
            "100%|██████████| 1242874899/1242874899 [00:35<00:00, 34618137.78B/s]\n",
            "10/18/2021 13:49:01: copying /tmp/tmpkkecojnc to cache at /root/.pytorch_pretrained_bert/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233\n",
            "10/18/2021 13:49:05: creating metadata file for /root/.pytorch_pretrained_bert/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233\n",
            "10/18/2021 13:49:05: removing temp file /tmp/tmpkkecojnc\n",
            "10/18/2021 13:49:06: loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz from cache at /root/.pytorch_pretrained_bert/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233\n",
            "10/18/2021 13:49:06: extracting archive file /root/.pytorch_pretrained_bert/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233 to temp dir /tmp/tmp64s9mvkq\n",
            "10/18/2021 13:49:34: Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"ffn_type\": 0,\n",
            "  \"fp32_embedding\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label_smoothing\": null,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"new_pos_ids\": false,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_qkv\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"relax_projection\": 0,\n",
            "  \"seg_emb\": false,\n",
            "  \"task_idx\": null,\n",
            "  \"type_vocab_size\": 6,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "10/18/2021 13:49:46: config.type_vocab_size != state_dict[bert.embeddings.token_type_embeddings.weight] (6 != 2)\n",
            "10/18/2021 13:50:25: Attempting to acquire lock 140622681406608 on /root/.cache/huggingface/transformers/c9961ea5b7e8ad58701728c45f4d225f70b19aa59745121e5a96c8a44efca4c8.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n",
            "10/18/2021 13:50:25: Lock 140622681406608 acquired on /root/.cache/huggingface/transformers/c9961ea5b7e8ad58701728c45f4d225f70b19aa59745121e5a96c8a44efca4c8.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e7d9f677e774af2bc68bc3df49d9cb2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10/18/2021 13:50:25: Attempting to release lock 140622681406608 on /root/.cache/huggingface/transformers/c9961ea5b7e8ad58701728c45f4d225f70b19aa59745121e5a96c8a44efca4c8.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n",
            "10/18/2021 13:50:25: Lock 140622681406608 released on /root/.cache/huggingface/transformers/c9961ea5b7e8ad58701728c45f4d225f70b19aa59745121e5a96c8a44efca4c8.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791.lock\n",
            "10/18/2021 13:50:26: Attempting to acquire lock 140622680381520 on /root/.cache/huggingface/transformers/45d2aa048795efc7b12791662c188d5e3aa2f9ac54b2cf3f6e4d7bc6544e3d13.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n",
            "10/18/2021 13:50:26: Lock 140622680381520 acquired on /root/.cache/huggingface/transformers/45d2aa048795efc7b12791662c188d5e3aa2f9ac54b2cf3f6e4d7bc6544e3d13.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e41e1173dd449a690183dadb84177b6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10/18/2021 13:50:26: Attempting to release lock 140622680381520 on /root/.cache/huggingface/transformers/45d2aa048795efc7b12791662c188d5e3aa2f9ac54b2cf3f6e4d7bc6544e3d13.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n",
            "10/18/2021 13:50:26: Lock 140622680381520 released on /root/.cache/huggingface/transformers/45d2aa048795efc7b12791662c188d5e3aa2f9ac54b2cf3f6e4d7bc6544e3d13.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n",
            "10/18/2021 13:50:26: Attempting to acquire lock 140622673056272 on /root/.cache/huggingface/transformers/75be22d7750034989358861e325977feda47740e1c3f8a4dc1cb73570aad843e.2b9a196704f2f183fe3f4b48d6e662dba8203fdcb3346bfa896831378edf6f97.lock\n",
            "10/18/2021 13:50:26: Lock 140622673056272 acquired on /root/.cache/huggingface/transformers/75be22d7750034989358861e325977feda47740e1c3f8a4dc1cb73570aad843e.2b9a196704f2f183fe3f4b48d6e662dba8203fdcb3346bfa896831378edf6f97.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "289abd6fe70b46b49bee2b845bfd0deb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10/18/2021 13:50:27: Attempting to release lock 140622673056272 on /root/.cache/huggingface/transformers/75be22d7750034989358861e325977feda47740e1c3f8a4dc1cb73570aad843e.2b9a196704f2f183fe3f4b48d6e662dba8203fdcb3346bfa896831378edf6f97.lock\n",
            "10/18/2021 13:50:27: Lock 140622673056272 released on /root/.cache/huggingface/transformers/75be22d7750034989358861e325977feda47740e1c3f8a4dc1cb73570aad843e.2b9a196704f2f183fe3f4b48d6e662dba8203fdcb3346bfa896831378edf6f97.lock\n",
            "10/18/2021 13:50:27: Attempting to acquire lock 140622629586192 on /root/.cache/huggingface/transformers/11ad22b0deaa199d15b331609ca5f60872a1a91473e9b40c115192dadb6d9a30.bdf0177a774dcff07681b2527b926c099e6563687c75a79f7469c7a7da7898c7.lock\n",
            "10/18/2021 13:50:27: Lock 140622629586192 acquired on /root/.cache/huggingface/transformers/11ad22b0deaa199d15b331609ca5f60872a1a91473e9b40c115192dadb6d9a30.bdf0177a774dcff07681b2527b926c099e6563687c75a79f7469c7a7da7898c7.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "507cfe6b5a464a1d9f7a32f31c640aa0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10/18/2021 13:50:27: Attempting to release lock 140622629586192 on /root/.cache/huggingface/transformers/11ad22b0deaa199d15b331609ca5f60872a1a91473e9b40c115192dadb6d9a30.bdf0177a774dcff07681b2527b926c099e6563687c75a79f7469c7a7da7898c7.lock\n",
            "10/18/2021 13:50:27: Lock 140622629586192 released on /root/.cache/huggingface/transformers/11ad22b0deaa199d15b331609ca5f60872a1a91473e9b40c115192dadb6d9a30.bdf0177a774dcff07681b2527b926c099e6563687c75a79f7469c7a7da7898c7.lock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkDtGPdVRC17",
        "outputId": "3bc4e6ca-b12c-4965-e9ce-b579be603f6c"
      },
      "source": [
        "!wget https://olmpics.s3.us-east-2.amazonaws.com/challenge/antonym_synonym_negation/antonym_synonym_negation_dev.jsonl.gz\n",
        "!wget https://olmpics.s3.us-east-2.amazonaws.com/challenge/size_comparison/size_comparison_dev.jsonl.gz\n",
        "!wget https://olmpics.s3.us-east-2.amazonaws.com/challenge/compositional_comparison/compositional_comparison_dev.jsonl.gz\n",
        "!wget https://olmpics.s3.us-east-2.amazonaws.com/challenge/number_comparison/number_comparison_age_compare_masked_dev.jsonl.gz\n",
        "!wget https://olmpics.s3.us-east-2.amazonaws.com/challenge/coffee_cats_quantifiers/coffee_cats_quantifiers_dev.jsonl.gz\n",
        "# !wget https://olmpics.s3.us-east-2.amazonaws.com/challenge/conjunction/conjunction_filt4_dev.jsonl.gz\n",
        "# !wget https://olmpics.s3.us-east-2.amazonaws.com/challenge/hypernym_conjunction/hypernym_conjunction_dev.jsonl.gz\n",
        "# !wget https://olmpics.s3.us-east-2.amazonaws.com/challenge/composition/composition_v2_dev.jsonl.gz"
      ],
      "id": "kkDtGPdVRC17",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-18 13:56:49--  https://olmpics.s3.us-east-2.amazonaws.com/challenge/antonym_synonym_negation/antonym_synonym_negation_dev.jsonl.gz\n",
            "Resolving olmpics.s3.us-east-2.amazonaws.com (olmpics.s3.us-east-2.amazonaws.com)... 52.219.101.66\n",
            "Connecting to olmpics.s3.us-east-2.amazonaws.com (olmpics.s3.us-east-2.amazonaws.com)|52.219.101.66|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17333 (17K) [binary/octet-stream]\n",
            "Saving to: ‘antonym_synonym_negation_dev.jsonl.gz’\n",
            "\n",
            "antonym_synonym_neg 100%[===================>]  16.93K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-10-18 13:56:49 (618 KB/s) - ‘antonym_synonym_negation_dev.jsonl.gz’ saved [17333/17333]\n",
            "\n",
            "--2021-10-18 13:56:49--  https://olmpics.s3.us-east-2.amazonaws.com/challenge/size_comparison/size_comparison_dev.jsonl.gz\n",
            "Resolving olmpics.s3.us-east-2.amazonaws.com (olmpics.s3.us-east-2.amazonaws.com)... 52.219.101.66\n",
            "Connecting to olmpics.s3.us-east-2.amazonaws.com (olmpics.s3.us-east-2.amazonaws.com)|52.219.101.66|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13400 (13K) [binary/octet-stream]\n",
            "Saving to: ‘size_comparison_dev.jsonl.gz’\n",
            "\n",
            "size_comparison_dev 100%[===================>]  13.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-18 13:56:50 (131 MB/s) - ‘size_comparison_dev.jsonl.gz’ saved [13400/13400]\n",
            "\n",
            "--2021-10-18 13:56:50--  https://olmpics.s3.us-east-2.amazonaws.com/challenge/compositional_comparison/compositional_comparison_dev.jsonl.gz\n",
            "Resolving olmpics.s3.us-east-2.amazonaws.com (olmpics.s3.us-east-2.amazonaws.com)... 52.219.101.66\n",
            "Connecting to olmpics.s3.us-east-2.amazonaws.com (olmpics.s3.us-east-2.amazonaws.com)|52.219.101.66|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14064 (14K) [binary/octet-stream]\n",
            "Saving to: ‘compositional_comparison_dev.jsonl.gz’\n",
            "\n",
            "compositional_compa 100%[===================>]  13.73K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-18 13:56:50 (103 MB/s) - ‘compositional_comparison_dev.jsonl.gz’ saved [14064/14064]\n",
            "\n",
            "--2021-10-18 13:56:50--  https://olmpics.s3.us-east-2.amazonaws.com/challenge/number_comparison/number_comparison_age_compare_masked_dev.jsonl.gz\n",
            "Resolving olmpics.s3.us-east-2.amazonaws.com (olmpics.s3.us-east-2.amazonaws.com)... 52.219.101.66\n",
            "Connecting to olmpics.s3.us-east-2.amazonaws.com (olmpics.s3.us-east-2.amazonaws.com)|52.219.101.66|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12544 (12K) [binary/octet-stream]\n",
            "Saving to: ‘number_comparison_age_compare_masked_dev.jsonl.gz’\n",
            "\n",
            "number_comparison_a 100%[===================>]  12.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-18 13:56:50 (86.5 MB/s) - ‘number_comparison_age_compare_masked_dev.jsonl.gz’ saved [12544/12544]\n",
            "\n",
            "--2021-10-18 13:56:50--  https://olmpics.s3.us-east-2.amazonaws.com/challenge/coffee_cats_quantifiers/coffee_cats_quantifiers_dev.jsonl.gz\n",
            "Resolving olmpics.s3.us-east-2.amazonaws.com (olmpics.s3.us-east-2.amazonaws.com)... 52.219.101.66\n",
            "Connecting to olmpics.s3.us-east-2.amazonaws.com (olmpics.s3.us-east-2.amazonaws.com)|52.219.101.66|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10241 (10K) [binary/octet-stream]\n",
            "Saving to: ‘coffee_cats_quantifiers_dev.jsonl.gz’\n",
            "\n",
            "coffee_cats_quantif 100%[===================>]  10.00K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-18 13:56:51 (120 MB/s) - ‘coffee_cats_quantifiers_dev.jsonl.gz’ saved [10241/10241]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCngy2LORS9c"
      },
      "source": [
        "!gunzip antonym_synonym_negation_dev.jsonl.gz\n",
        "!gunzip compositional_comparison_dev.jsonl.gz\n",
        "!gunzip size_comparison_dev.jsonl.gz\n",
        "!gunzip coffee_cats_quantifiers_dev.jsonl.gz\n",
        "!gunzip number_comparison_age_compare_masked_dev.jsonl.gz\n",
        "# !gunzip conjunction_filt4_dev.jsonl.gz\n",
        "# !gunzip hypernym_conjunction_dev.jsonl.gz\n",
        "# !gunzip composition_v2_dev.jsonl.gz"
      ],
      "id": "PCngy2LORS9c",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca81746e",
        "outputId": "ba77a62c-7ac8-4040-b023-545aae55f9a7"
      },
      "source": [
        "'''\n",
        "Mask_task MC-MLM\n",
        "\"coffee_cats_quantifiers_dev.jsonl\"   num_choices = 5 , Always-Never\n",
        "\"size_comparison_dev.jsonl\" num_choices = 2 , Object comparison\n",
        "\"antonym_synonym_negation_dev.jsonl\" num_choices = 2\n",
        "\"number_comparison_age_compare_masked_dev.jsonl\"  num_choices = 2\n",
        "\"compositional_comparison_dev.jsonl\" , args.num_choices = 3 , multihop composition\n",
        "\n",
        "'''\n",
        "train_path = \"coffee_cats_quantifiers_dev.jsonl\"\n",
        "data  = train_path\n",
        "args.num_choices = 5\n",
        "eval_path = train_path\n",
        "train_questions, train_choices, train_answer_ids = get_data(train_path, args.sample_train, args.num_choices)\n",
        "eval_questions, eval_choices, eval_answer_ids = get_data(eval_path, args.sample_eval, args.num_choices)\n",
        "AgeDataset = RoBERTaDataset if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\", \"distil\", \"electra\", \"t5\")) else BERTDataset\n",
        "train_dataset = AgeDataset(train_questions, train_choices, train_answer_ids, tokenizer)\n",
        "#eval_dataset = AgeDataset(eval_questions, eval_choices, eval_answer_ids, tokenizer)"
      ],
      "id": "ca81746e",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10/18/2021 13:57:16: Reading QA instances from jsonl dataset at: coffee_cats_quantifiers_dev.jsonl\n",
            "10/18/2021 13:57:16: Sampling 200 examples\n",
            "100%|██████████| 200/200 [00:00<00:00, 56891.20it/s]\n",
            "10/18/2021 13:57:16: Reading QA instances from jsonl dataset at: coffee_cats_quantifiers_dev.jsonl\n",
            "100%|██████████| 280/280 [00:00<00:00, 205747.22it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOppKWb46MHp"
      },
      "source": [
        "def get_sentence_prob(input_ids, logits):\n",
        "    # Multiplies together individual probabilities to get overall sentence probability\n",
        "    logits = torch.nn.functional.softmax(logits, dim=2)\n",
        "    probs = torch.gather(logits, 2, input_ids.unsqueeze(-1))\n",
        "    probs = probs.squeeze(-1)\n",
        "    probs = probs * 1e4  # product is zero otherwise\n",
        "    #probs = torch.prod(probs, dim=1)\n",
        "    probs = torch.sum(torch.log(probs), dim=1)\n",
        "    return probs"
      ],
      "id": "WOppKWb46MHp",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYOcJBZn9ZPg"
      },
      "source": [
        "def evaluate(args, model, tokenizer, eval_dataset):\n",
        "    eval_sampler = SequentialSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.per_device_eval_batch_size)\n",
        "\n",
        "    logger.info(f\"***** Running evaluation  *****\")\n",
        "    logger.info(f\"  Num examples = {len(eval_dataset)}\")\n",
        "    logger.info(f\"  Batch size = {args.eval_batch_size}\")\n",
        "    eval_dataloader = tqdm(eval_dataloader, desc=\"Evaluating\")\n",
        "    \n",
        "    print(tokenizer.mask_token)\n",
        "    MASK_ID = tokenizer.encode(tokenizer.mask_token, add_special_tokens=False)\n",
        "    assert len(MASK_ID) == 1\n",
        "    MASK_ID = MASK_ID[0]\n",
        "    \n",
        "    all_answers = []\n",
        "    all_preds = []\n",
        "    for batch in eval_dataloader:\n",
        "        model.eval()\n",
        "        \n",
        "        # batch[\"choice_list\"] is [num_choices, batch_size]\n",
        "        for i in range(len(batch[\"choice_list\"][0])):\n",
        "            all_answers.append(batch[\"choice_list\"][batch[\"answer_id\"][i]][i])\n",
        "        \n",
        "        choice_lists = batch.pop(\"choice_list\")\n",
        "        \n",
        "        del batch[\"answer_id\"] \n",
        "        for key in batch:\n",
        "            batch[key] = torch.stack(batch[key], dim=-1).cuda()\n",
        "       \n",
        "        for i in range(len(batch[\"input_ids\"])):\n",
        "          question = batch[\"input_ids\"][i]\n",
        "        \n",
        "        with torch.no_grad():\n",
        "           \n",
        "            outputs = model(**batch)\n",
        "            logits = outputs[0]\n",
        "            choice_ids = []\n",
        "\n",
        "            for i, logit in enumerate(logits):  # Assuming all are single tokens\n",
        "              #print(batch[\"input_ids\"][i])\n",
        "              #print(tokenizer.convert_ids_to_tokens(batch[\"input_ids\"][i]))\n",
        "              MASK_INDEX = batch[\"input_ids\"][i].tolist().index(MASK_ID)\n",
        "              #print(MASK_INDEX)\n",
        "              choice_ids = torch.tensor([tokenizer.encode(\" \" + choice_lists[j][i], add_special_tokens=False)[0] for j in range(len(choice_lists))])\n",
        "              choice_ids = choice_ids.cuda()\n",
        "              #print(\"choices_ids after logits \", choice_ids)\n",
        "              probs = logit[MASK_INDEX].index_select(0, choice_ids).cuda()\n",
        "              #print(\"probabilities \", probs)\n",
        "              max_ind = torch.argmax(probs)\n",
        "              #print(\"max_index  \", max_ind)\n",
        "              all_preds.append(choice_lists[max_ind][i])\n",
        "\n",
        "    return all_answers, all_preds"
      ],
      "id": "RYOcJBZn9ZPg",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAoHC8QO8QgP"
      },
      "source": [
        "def evaluate_taskwithmask(args, model, tokenizer, eval_dataset, data_path):\n",
        "    \n",
        "    eval_sampler = SequentialSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.per_device_eval_batch_size)\n",
        "\n",
        "    logger.info(f\"***** Running evaluation  *****\")\n",
        "    logger.info(f\"  Num examples = {len(eval_dataset)}\")\n",
        "    logger.info(f\"  Batch size = {args.eval_batch_size}\")\n",
        "    eval_dataloader = tqdm(eval_dataloader, desc=\"Evaluating\")\n",
        "    \n",
        "    #encoding all the labels\n",
        "    label_dict = {}\n",
        "    label_encodings = {}\n",
        "    list_of_labels = eval_dataset[0]['choice_list']\n",
        "    i=0\n",
        "    for label in list_of_labels:\n",
        "      label_dict[label] = i\n",
        "      label1 = \" \"+ label\n",
        "      label_encodings[label1] = tokenizer.encode(label1, add_special_tokens=False)[0]\n",
        "      i+=1\n",
        "\n",
        "    label_id_encoding_map = dict(zip(label_dict.values(),label_encodings.values()))\n",
        "\n",
        "    all_answers = []\n",
        "    all_preds = []\n",
        "    first_age = []\n",
        "    second_age = []\n",
        "    first_object = []\n",
        "    second_object = []\n",
        "    \n",
        "    #create list of true answers =  all_answers \n",
        "    for batch in eval_dataloader:\n",
        "        original_batch = batch          \n",
        "        model.eval()\n",
        "        for i in range(len(batch[\"answer_id\"])):\n",
        "            true_label_id = batch[\"answer_id\"][i]\n",
        "            actual_label = batch[\"choice_list\"][true_label_id][i]\n",
        "            label_id_to_append = label_dict[actual_label]\n",
        "            all_answers.append(label_id_to_append)\n",
        "           \n",
        "\n",
        "        del batch[\"choice_list\"] \n",
        "        for key in batch:\n",
        "            if key != \"answer_id\":\n",
        "                batch[key] = torch.stack(batch[key], dim=-1)\n",
        "\n",
        "            batch[key] = batch[key].cuda()\n",
        "      \n",
        "        \n",
        "        answer_ids = batch.pop(\"answer_id\")\n",
        "        label_encoding_list = list(label_encodings.values())\n",
        "        no_of_labels = len(label_encoding_list)\n",
        "\n",
        "        #create the list for age1, age2 for age task and list of objects for object comparison task\n",
        "        if data_path == \"number_comparison_age_compare_masked_dev.jsonl\":\n",
        "            age1 = tokenizer.decode(batch[\"input_ids\"][:, 1]).split(\" \")\n",
        "            age2 = tokenizer.decode(batch[\"input_ids\"][:, 11]).split(\" \")\n",
        "            age1 = age1[1:]\n",
        "            age2 = age2[1:]\n",
        "            first_age.extend(age1)\n",
        "            second_age.extend(age2)\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            #generate probablities for all the labels\n",
        "            \n",
        "            list_of_mask_index = []\n",
        "           \n",
        "            for i in range(len(batch[\"input_ids\"])):\n",
        "                  question = batch[\"input_ids\"][i]\n",
        "                  MASK_INDEX = (question==tokenizer.mask_token_id).nonzero().item()\n",
        "                  batch[\"input_ids\"][i, MASK_INDEX] =  label_id_encoding_map[0]\n",
        "                  list_of_mask_index.append(MASK_INDEX)\n",
        "            \n",
        "            outputs = model(**batch)\n",
        "            logits = outputs[0]\n",
        "            id0_prob = get_sentence_prob(batch[\"input_ids\"], logits)\n",
        "           \n",
        "            m=0\n",
        "            for i in range(len(batch[\"input_ids\"])):\n",
        "                question = batch[\"input_ids\"][i]\n",
        "                MASK_INDEX = list_of_mask_index[m]\n",
        "                batch[\"input_ids\"][i, MASK_INDEX] =  label_id_encoding_map[1]\n",
        "                m +=1\n",
        "      \n",
        "            outputs = model(**batch)\n",
        "            logits = outputs[0]\n",
        "            id1_prob = get_sentence_prob(batch[\"input_ids\"], logits)\n",
        "            \n",
        "            if no_of_labels==3:\n",
        "              m=0\n",
        "              for i in range(len(batch[\"input_ids\"])):\n",
        "                  question = batch[\"input_ids\"][i]\n",
        "                  MASK_INDEX = list_of_mask_index[m]\n",
        "                  batch[\"input_ids\"][i, MASK_INDEX] =  label_id_encoding_map[2]\n",
        "                  m +=1\n",
        "                  \n",
        "              outputs = model(**batch)\n",
        "              logits = outputs[0]\n",
        "              id2_prob = get_sentence_prob(batch[\"input_ids\"], logits)\n",
        "\n",
        "            if no_of_labels==5:\n",
        "                m=0\n",
        "                for i in range(len(batch[\"input_ids\"])):\n",
        "                    question = batch[\"input_ids\"][i]\n",
        "                    MASK_INDEX = list_of_mask_index[m]\n",
        "                    batch[\"input_ids\"][i, MASK_INDEX] =  label_id_encoding_map[2]\n",
        "                    m +=1\n",
        "                \n",
        "                outputs = model(**batch)\n",
        "                logits = outputs[0]\n",
        "                id2_prob = get_sentence_prob(batch[\"input_ids\"], logits)\n",
        "\n",
        "                m=0\n",
        "                for i in range(len(batch[\"input_ids\"])):\n",
        "                    question = batch[\"input_ids\"][i]\n",
        "                    MASK_INDEX = list_of_mask_index[m]\n",
        "                    batch[\"input_ids\"][i, MASK_INDEX] =  label_id_encoding_map[3]\n",
        "                    m +=1\n",
        "                outputs = model(**batch)\n",
        "                logits = outputs[0]\n",
        "                id3_prob = get_sentence_prob(batch[\"input_ids\"], logits)\n",
        "\n",
        "                m=0\n",
        "                for i in range(len(batch[\"input_ids\"])):\n",
        "                    question = batch[\"input_ids\"][i]\n",
        "                    MASK_INDEX = list_of_mask_index[m]\n",
        "                    batch[\"input_ids\"][i, MASK_INDEX] =  label_id_encoding_map[4]\n",
        "                    m +=1\n",
        "                  \n",
        "                outputs = model(**batch)\n",
        "                logits = outputs[0]\n",
        "                id4_prob = get_sentence_prob(batch[\"input_ids\"], logits)\n",
        "  \n",
        "        batch_size = len(batch[\"input_ids\"])\n",
        "        #create all_preds\n",
        "        if no_of_labels ==2:\n",
        "          test_pred = torch.gt(id0_prob, id0_prob)\n",
        "          id0_prob = torch.reshape(id0_prob, (batch_size, 1))\n",
        "          id1_prob = torch.reshape(id1_prob, (batch_size, 1))\n",
        "          combine_prob = torch.cat((id0_prob, id1_prob), dim=1)\n",
        "          preds = list(torch.argmax(combine_prob, dim=1))\n",
        "          all_preds.extend(preds)\n",
        "        elif no_of_labels ==3:\n",
        "          id0_prob = torch.reshape(id0_prob, (batch_size, 1))\n",
        "          id1_prob = torch.reshape(id1_prob, (batch_size, 1))\n",
        "          id2_prob = torch.reshape(id2_prob, (batch_size, 1))\n",
        "          combine_prob = torch.cat((id0_prob, id1_prob, id2_prob), dim=1)\n",
        "          preds = list(torch.argmax(combine_prob, dim=1))\n",
        "          all_preds.extend(preds)\n",
        "        elif no_of_labels ==5:\n",
        "          id0_prob = torch.reshape(id0_prob, (batch_size, 1))\n",
        "          id1_prob = torch.reshape(id1_prob,(batch_size, 1))\n",
        "          id2_prob = torch.reshape(id2_prob, (batch_size, 1))\n",
        "          id3_prob = torch.reshape(id3_prob, (batch_size, 1))\n",
        "          id4_prob = torch.reshape(id4_prob, (batch_size, 1))\n",
        "          combine_prob = torch.cat((id0_prob, id1_prob, id2_prob, id3_prob, id4_prob), dim=1)\n",
        "          preds = list(torch.argmax(combine_prob, dim=1))\n",
        "          all_preds.extend(preds)\n",
        "    return all_answers, all_preds"
      ],
      "id": "OAoHC8QO8QgP",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFLzFpa3AxtO",
        "outputId": "3e2f65de-e713-406c-fb35-a71874dc461a"
      },
      "source": [
        "#choose random 80% of the dataset and run evaluation for 5 cycles\n",
        "accuracy = []\n",
        "for i in range(5):\n",
        "  eval_questions, eval_choices, eval_answer_ids = get_data(data, args.sample_eval, args.num_choices)\n",
        "  combined_dataset = {'que': eval_questions, 'choices': eval_choices, 'ids': eval_answer_ids, }\n",
        "  combined_dataset = pd.DataFrame(data=combined_dataset)\n",
        "  sampled_dataset = combined_dataset.sample(frac = 0.8)\n",
        "  eval_questions = list(sampled_dataset['que'])\n",
        "  eval_choices = list(sampled_dataset['choices'])\n",
        "  eval_answer_ids = list(sampled_dataset['ids'])\n",
        "\n",
        "  eval_dataset = AgeDataset(eval_questions, eval_choices, eval_answer_ids, tokenizer)\n",
        "  all_answers, all_preds = evaluate(args, model, tokenizer, eval_dataset)\n",
        "  a = 0\n",
        "  b = 0\n",
        "  for i in range(len(all_answers)):\n",
        "    if all_preds[i] != -1:\n",
        "        b += 1\n",
        "        if all_preds[i] == all_answers[i]:\n",
        "            a += 1\n",
        "  current_acc = a/b\n",
        "  accuracy.append(current_acc)"
      ],
      "id": "DFLzFpa3AxtO",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10/18/2021 13:57:32: Reading QA instances from jsonl dataset at: coffee_cats_quantifiers_dev.jsonl\n",
            "100%|██████████| 280/280 [00:00<00:00, 61096.93it/s]\n",
            "10/18/2021 13:57:32: ***** Running evaluation  *****\n",
            "10/18/2021 13:57:32:   Num examples = 224\n",
            "10/18/2021 13:57:32:   Batch size = 2\n",
            "Evaluating:   0%|          | 0/112 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MASK]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 112/112 [00:07<00:00, 15.13it/s]\n",
            "10/18/2021 13:57:40: Reading QA instances from jsonl dataset at: coffee_cats_quantifiers_dev.jsonl\n",
            "100%|██████████| 280/280 [00:00<00:00, 120538.35it/s]\n",
            "10/18/2021 13:57:40: ***** Running evaluation  *****\n",
            "10/18/2021 13:57:40:   Num examples = 224\n",
            "10/18/2021 13:57:40:   Batch size = 2\n",
            "Evaluating:   2%|▏         | 2/112 [00:00<00:06, 15.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MASK]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 112/112 [00:06<00:00, 16.04it/s]\n",
            "10/18/2021 13:57:47: Reading QA instances from jsonl dataset at: coffee_cats_quantifiers_dev.jsonl\n",
            "100%|██████████| 280/280 [00:00<00:00, 112415.54it/s]\n",
            "10/18/2021 13:57:47: ***** Running evaluation  *****\n",
            "10/18/2021 13:57:47:   Num examples = 224\n",
            "10/18/2021 13:57:47:   Batch size = 2\n",
            "Evaluating:   2%|▏         | 2/112 [00:00<00:07, 15.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MASK]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 112/112 [00:06<00:00, 16.05it/s]\n",
            "10/18/2021 13:57:54: Reading QA instances from jsonl dataset at: coffee_cats_quantifiers_dev.jsonl\n",
            "100%|██████████| 280/280 [00:00<00:00, 159783.01it/s]\n",
            "10/18/2021 13:57:54: ***** Running evaluation  *****\n",
            "10/18/2021 13:57:54:   Num examples = 224\n",
            "10/18/2021 13:57:54:   Batch size = 2\n",
            "Evaluating:   2%|▏         | 2/112 [00:00<00:06, 16.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MASK]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 112/112 [00:06<00:00, 16.05it/s]\n",
            "10/18/2021 13:58:01: Reading QA instances from jsonl dataset at: coffee_cats_quantifiers_dev.jsonl\n",
            "100%|██████████| 280/280 [00:00<00:00, 102639.85it/s]\n",
            "10/18/2021 13:58:01: ***** Running evaluation  *****\n",
            "10/18/2021 13:58:01:   Num examples = 224\n",
            "10/18/2021 13:58:01:   Batch size = 2\n",
            "Evaluating:   2%|▏         | 2/112 [00:00<00:07, 14.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MASK]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 112/112 [00:06<00:00, 16.04it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu6gHNZdA5V8",
        "outputId": "4a009c42-cf84-4db9-f65c-b8d996c24d76"
      },
      "source": [
        "accuracy"
      ],
      "id": "pu6gHNZdA5V8",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16964285714285715, 0.1875, 0.21428571428571427, 0.1875, 0.20089285714285715]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP7GR10iA7g7"
      },
      "source": [
        "#Number of samples = 5\n",
        "#create 95% confidence interval for population mean weight\n",
        "mini, maxi = st.t.interval(alpha=0.95, df=len(accuracy)-1, loc=np.mean(accuracy), scale=st.sem(accuracy))\n",
        "accuracy = np.array(accuracy)"
      ],
      "id": "nP7GR10iA7g7",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l___xO9tBDOo",
        "outputId": "0ca4f662-f888-4ac5-f770-e28fc24984af"
      },
      "source": [
        "print(\"The accuracy is of {} for {} task is {} +- {}\".format(args.model_name_or_path, train_path, accuracy.mean()*100 ,-1*accuracy.mean()*100+maxi*100))"
      ],
      "id": "l___xO9tBDOo",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is of bert-large-cased for coffee_cats_quantifiers_dev.jsonl task is 19.196428571428573 +- 2.0740541387367806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnvZhLFhCD-I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "5958ac41-bccb-4b2f-ac95-00b9b1faef1c"
      },
      "source": [
        "#unilm-base\n",
        "\n",
        "#The accuracy is of unilm-base for coffee_cats_quantifiers_dev.jsonl task \n",
        "#[0.16517857142857142,\n",
        " 0.14732142857142858,\n",
        " 0.16517857142857142,\n",
        " 0.16071428571428573,\n",
        " 0.13839285714285715]\n",
        " # 15.535714285714283 +- 1.4873813063559655\n",
        "\n",
        "#The accuracy is of unilm-base for size_comparison_dev.jsonl task is \n",
        "#[0.485, 0.4875, 0.475, 0.4825, 0.4625]\n",
        "# 47.849999999999994 +- 1.2532505385071673\n",
        "\n",
        "\n",
        "#The accuracy is of unilm-base for antonym_synonym_negation_dev.jsonl task is \n",
        "#[0.4425, 0.4275, 0.4325, 0.4375, 0.4325]\n",
        "#43.45 +- 0.707857388491135\n",
        "\n",
        "#The accuracy is of unilm-base for compositional_comparison_dev.jsonl task is \n",
        "#[0.35, 0.3525, 0.3375, 0.3525, 0.35]\n",
        "#34.85 +- 0.779137975262671\n",
        "\n",
        "#The accuracy is of unilm-base for number_comparison_age_compare_masked_dev.jsonl task is \n",
        "#[0.4875, 0.48, 0.4725, 0.46, 0.4925]\n",
        "#47.85 +- 1.5919226865776608\n",
        "\n",
        "#5parts\n",
        "#[0.4075, 0.4525, 0.515, 0.5475, 0.6075]\n",
        "# 50.6 +- 9.751213563067473\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "MnvZhLFhCD-I",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-a70644c8346e>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    0.14732142857142858,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQi0rFeOCfRt"
      },
      "source": [
        "#unilm-large\n",
        "\n",
        "#The accuracy is of unilm-base for coffee_cats_quantifiers_dev.jsonl task \n",
        "#[0.16964285714285715, 0.1875, 0.21428571428571427, 0.1875, 0.20089285714285715]\n",
        "#19.196428571428573 +- 2.0740541387367806\n",
        "\n",
        "#The accuracy is of unilm-base for size_comparison_dev.jsonl task \n",
        "#[0.5975, 0.605, 0.61, 0.6275, 0.6175]\n",
        "# 61.150000000000006 +- 1.4326295320684181\n",
        "\n",
        "#The accuracy is of unilm-base for antonym_synonym_negation_dev.jsonl task is \n",
        "#[0.5075, 0.5175, 0.5025, 0.51, 0.5025]\n",
        "# 50.79999999999999 +- 0.7729296056037143\n",
        "\n",
        "#The accuracy is of unilm-base for compositional_comparison_dev.jsonl task is\n",
        "#[0.345, 0.3175, 0.3325, 0.33, 0.33]\n",
        "#33.1 +- 1.21419883853153\n",
        "\n",
        "#The accuracy is of unilm-base for number_comparison_age_compare_masked_dev.jsonl task is \n",
        "#[0.4875, 0.48, 0.4725, 0.46, 0.4925]\n",
        "# 47.85 +- 1.5919226865776608\n",
        "#5parts\n",
        "#[0.375, 0.42, 0.48, 0.5325, 0.5725]\n",
        "# 47.599999999999994 +- 9.983144562685077\n"
      ],
      "id": "qQi0rFeOCfRt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b6e8937"
      },
      "source": [
        "if train_path == 'number_comparison_age_compare_masked_dev.jsonl':\n",
        "  all_answers, all_preds = evaluate_taskwithmask(args, model, tokenizer, eval_dataset, train_path)\n",
        "  #only for number comparison\n",
        "  #run the evaluation for five times to capture variation in the results. Dataset is divided into 5 parts and one part is dropped with each evaluation cycle.\n",
        "\n",
        "  accuracy = []\n",
        "  for i in range(5):\n",
        "    eval_questions, eval_choices, eval_answer_ids = get_data(train_path, args.sample_eval, args.num_choices)\n",
        "    total_items = len(eval_questions)\n",
        "    n = int(total_items/5)\n",
        "    if i==0:\n",
        "      eval_questions = eval_questions[n:]\n",
        "      eval_choices = eval_choices[n:]\n",
        "      eval_answer_ids = eval_answer_ids[n:] \n",
        "    elif i==4:\n",
        "      eval_questions = eval_questions[:4*n]\n",
        "      eval_choices = eval_choices[:4*n]\n",
        "      eval_answer_ids = eval_answer_ids[:4*n]\n",
        "      \n",
        "    else:\n",
        "      eval_questions = eval_questions[:i*n] + eval_questions[(i+1)*n:]\n",
        "      eval_choices = eval_choices[:i*n] + eval_choices[(i+1)*n:]\n",
        "      eval_answer_ids = eval_answer_ids[:i*n] + eval_answer_ids[(i+1)*n:]   \n",
        "\n",
        "    eval_dataset = AgeDataset(eval_questions, eval_choices, eval_answer_ids, tokenizer)\n",
        "    print(len(eval_dataset))\n",
        "    #if train_path == \"hypernym_conjunction_dev.jsonl\" or train_path ==\"composition_v2_dev.jsonl\" or train_path==\"conjunction_filt4_dev.jsonl\":\n",
        "    #all_answers, all_preds = evaluateqa(args, model, tokenizer, eval_dataset, train_path)\n",
        "    #else:\n",
        "    all_answers, all_preds = evaluateqa(args, model, tokenizer, eval_dataset)\n",
        "    a = 0\n",
        "    b = 0\n",
        "    for i in range(len(all_answers)):\n",
        "      if all_preds[i] != -1:\n",
        "          b += 1\n",
        "          if all_preds[i] == all_answers[i]:\n",
        "              a += 1\n",
        "    current_acc = a/b\n",
        "    accuracy.append(current_acc)\n",
        "\n"
      ],
      "id": "7b6e8937",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKJSnIc-JIBU"
      },
      "source": [
        "accuracy"
      ],
      "id": "qKJSnIc-JIBU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM1WPB0WJLZm"
      },
      "source": [
        "#Number of samples = 5\n",
        "#create 95% confidence interval for population mean weight\n",
        "mini, maxi = st.t.interval(alpha=0.95, df=len(accuracy)-1, loc=np.mean(accuracy), scale=st.sem(accuracy))\n",
        "accuracy = np.array(accuracy)"
      ],
      "id": "HM1WPB0WJLZm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eLdsX4yJOFW"
      },
      "source": [
        "print(\"The accuracy is of {} for {} task is {} +- {}\".format(args.model_name_or_path, train_path, accuracy.mean()*100 ,-1*accuracy.mean()*100+maxi*100))"
      ],
      "id": "7eLdsX4yJOFW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxvU6EKshnLy"
      },
      "source": [
        "#5 parts\n",
        "#unilm-base\n",
        "#The accuracy is of unilm-base for compositional_comparison_dev.jsonl task is 34.8 +- 0.8888961473496906\n",
        "#[0.3475, 0.3375, 0.3575, 0.3475, 0.35]\n",
        "\n",
        "#The accuracy is of unilm-base for antonym_synonym_negation_dev.jsonl task is 43.599999999999994 +- 1.291121607380866\n",
        "#[0.44 0.4275 0.4525 0.43   0.43  ]\n",
        "\n",
        "#The accuracy is of unilm-base for number_comparison_age_compare_masked_dev.jsonl task is 49.400000000000006 +- 9.75121356306746\n",
        "#[0.5925 0.5475 0.485  0.4525 0.3925]\n",
        "\n",
        "#The accuracy is of unilm-base for size_comparison_dev.jsonl task is 48.0 +- 2.624805446803734\n",
        "#[0.5175, 0.47, 0.4675, 0.47, 0.475]\n",
        "\n",
        "#The accuracy is of unilm-base for coffee_cats_quantifiers_dev.jsonl task is 16.07142857142857 +- 0.7839187795402545\n",
        "#\n",
        "[0.15178571428571427, 0.16964285714285715, 0.16071428571428573, 0.16071428571428573, 0.16071428571428573]"
      ],
      "id": "TxvU6EKshnLy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiHgiT4A-H3A"
      },
      "source": [
        ""
      ],
      "id": "FiHgiT4A-H3A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJhhcCwCujb8"
      },
      "source": [
        "#5 parts\n",
        "#unilm-large\n",
        "\n",
        "#The accuracy is of unilm-large for compositional_comparison_dev.jsonl task is 33.599999999999994 +- 0.7146312977467488\n",
        "#[0.3375, 0.33, 0.345, 0.3325, 0.335]\n",
        "\n",
        "#The accuracy is of unilm-large for antonym_synonym_negation_dev.jsonl task is 51.19999999999999 +- 1.3777715440925036\n",
        "#[0.52, 0.505, 0.525, 0.4975, 0.5125]\n",
        "\n",
        "#The accuracy is of unilm-large for number_comparison_age_compare_masked_dev.jsonl task is 47.599999999999994 +- 9.98314456268507\n",
        "#[0.375, 0.42, 0.48, 0.5325, 0.5725]\n",
        "\n",
        "#The accuracy is of unilm-large for size_comparison_dev.jsonl task is 61.40000000000001 +- 1.8046893183785642\n",
        "#[0.6025, 0.6275, 0.5975, 0.63, 0.6125]\n",
        "\n",
        "#The accuracy is of unilm-large for coffee_cats_quantifiers_dev.jsonl task is 18.928571428571427 +- 1.3349655776296\n",
        "#[0.19196428571428573, 0.19642857142857142, 0.17410714285714285, 0.18303571428571427, 0.20089285714285715]"
      ],
      "id": "BJhhcCwCujb8",
      "execution_count": null,
      "outputs": []
    }
  ]
}